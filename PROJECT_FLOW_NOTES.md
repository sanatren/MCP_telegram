# Gemma Voice Assistant + Telegram MCP Integration - Detailed Project Flow

## ğŸ¯ Project Overview
A voice-activated AI assistant (like Siri) that uses local Ollama LLM for responses and integrates with Telegram messaging via MCP (Model Context Protocol). Users can speak naturally to send messages, get information, and control Telegram through voice commands.

---

## ğŸ“ System Architecture

### High-Level Components
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER INTERACTION                        â”‚
â”‚          Voice Input â†’ Microphone â†’ Audio Processing         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VOICE ASSISTANT CORE                      â”‚
â”‚  â€¢ Auto Voice Assistant (auto_voice_assistant.py)           â”‚
â”‚  â€¢ Activation Detection (Hello, Hi, Computer, Assistant)     â”‚
â”‚  â€¢ Conversation Management (60s timeout like Siri)           â”‚
â”‚  â€¢ Speech-to-Text (OpenAI gpt-4o-mini-transcribe)          â”‚
â”‚  â€¢ Text-to-Speech (Local pyttsx3 or OpenAI TTS)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INTENT UNDERSTANDING                     â”‚
â”‚  â€¢ Intent Parser (intent_parser.py)                         â”‚
â”‚  â€¢ GPT-4o-mini for natural language understanding           â”‚
â”‚  â€¢ Context-aware (tracks conversation history)              â”‚
â”‚  â€¢ Distinguishes: Message sending vs General chat           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                        â”‚
          â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TELEGRAM PATH   â”‚    â”‚   GENERAL CHAT PATH  â”‚
â”‚  (if message     â”‚    â”‚   (if casual conv.)  â”‚
â”‚   intent)        â”‚    â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP CLIENT      â”‚    â”‚  OLLAMA LLM          â”‚
â”‚  (mcp_client.py) â”‚    â”‚  (gemma2:2b)         â”‚
â”‚                  â”‚    â”‚  Local inference     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â–¼                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  MCP SERVER      â”‚            â”‚
â”‚  (telegram_      â”‚            â”‚
â”‚   server.py)     â”‚            â”‚
â”‚  Stdio protocol  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
         â”‚                      â”‚
         â–¼                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  TELETHON USER   â”‚            â”‚
â”‚  CLIENT          â”‚            â”‚
â”‚  (telethon_user_ â”‚            â”‚
â”‚   client.py)     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
         â”‚                      â”‚
         â–¼                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  TELEGRAM API    â”‚            â”‚
â”‚  (Sends message  â”‚            â”‚
â”‚   from user      â”‚            â”‚
â”‚   account)       â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   RESPONSE       â”‚
           â”‚   Spoken to user â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Detailed Flow Diagrams

### 1ï¸âƒ£ VOICE ACTIVATION FLOW
```
START: Background listening mode
   â”‚
   â”œâ”€â–º Record 2-second audio chunk
   â”‚      â”‚
   â”‚      â”œâ”€â–º Check volume threshold (> 0.008)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€ NO â†’ Continue listening
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€ YES â†’ Send to OpenAI Whisper API
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º Transcribe audio
   â”‚      â”‚              â”‚
   â”‚      â”‚              â””â”€â–º Check for activation words
   â”‚      â”‚                     [hello, hi, computer, assistant]
   â”‚      â”‚                     â”‚
   â”‚      â”‚                     â”œâ”€ NO â†’ Continue listening
   â”‚      â”‚                     â”‚
   â”‚      â”‚                     â””â”€ YES â†’ START CONVERSATION
   â”‚      â”‚                              â”‚
   â”‚      â”‚                              â”œâ”€â–º Play "Hi! What can I help you with?"
   â”‚      â”‚                              â”œâ”€â–º Set 60s timeout timer
   â”‚      â”‚                              â”œâ”€â–º Clear conversation history
   â”‚      â”‚                              â””â”€â–º Enter conversation loop
   â”‚      â”‚
   â”‚      â””â”€â–º Loop back to start
   â”‚
   â””â”€â–º Repeat continuously
```

### 2ï¸âƒ£ CONVERSATION FLOW (Active Session)
```
CONVERSATION ACTIVE (60s timeout running)
   â”‚
   â”œâ”€â–º Record 8-second audio chunk
   â”‚      â”‚
   â”‚      â”œâ”€â–º Check volume threshold (> 0.004)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€ NO â†’ Show "Silence..." message
   â”‚      â”‚      â”‚      â””â”€â–º Check timeout (elapsed > 60s?)
   â”‚      â”‚      â”‚            â”œâ”€ YES â†’ End conversation, speak goodbye
   â”‚      â”‚      â”‚            â””â”€ NO â†’ Continue waiting
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€ YES â†’ Transcribe with OpenAI
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º Get user text
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º RESET 60s timer (user spoke!)
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º Check for exit commands
   â”‚      â”‚              â”‚      [goodbye, bye, thanks, that's all, stop, exit]
   â”‚      â”‚              â”‚      â”‚
   â”‚      â”‚              â”‚      â”œâ”€ YES â†’ End conversation, speak goodbye
   â”‚      â”‚              â”‚      â”‚
   â”‚      â”‚              â”‚      â””â”€ NO â†’ Process user input
   â”‚      â”‚              â”‚              â”‚
   â”‚      â”‚              â”‚              â””â”€â–º GO TO: INTENT UNDERSTANDING FLOW
   â”‚      â”‚              â”‚
   â”‚      â”‚              â””â”€â–º After response:
   â”‚      â”‚                     â”œâ”€â–º Log to conversations.json
   â”‚      â”‚                     â”œâ”€â–º Speak response
   â”‚      â”‚                     â””â”€â–º Loop back (with reset timer)
   â”‚      â”‚
   â”‚      â””â”€â–º Check timeout before next iteration
   â”‚             â”‚
   â”‚             â”œâ”€ Timeout reached â†’ End conversation
   â”‚             â”‚
   â”‚             â””â”€ Time remaining â†’ Continue loop
   â”‚
   â””â”€â–º Exit: Return to listening mode
```

### 3ï¸âƒ£ INTENT UNDERSTANDING FLOW
```
USER TEXT INPUT
   â”‚
   â”œâ”€â–º Pass to IntentParser.parse(user_text, conversation_history)
   â”‚      â”‚
   â”‚      â”œâ”€â–º Build context from recent conversation
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Include last 3 message exchanges
   â”‚      â”‚      â”œâ”€â–º Track recipients from previous messages
   â”‚      â”‚      â””â”€â–º Handle pronouns (him, her, them) using context
   â”‚      â”‚
   â”‚      â”œâ”€â–º Send to GPT-4o-mini with system prompt
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º System: You are intent parser...
   â”‚      â”‚      â”œâ”€â–º Context: Recent conversation with recipients...
   â”‚      â”‚      â””â”€â–º User: Analyze this command: "{user_text}"
   â”‚      â”‚
   â”‚      â”œâ”€â–º GPT-4o-mini returns JSON
   â”‚      â”‚      {
   â”‚      â”‚        "action": "send_message" | "general_chat",
   â”‚      â”‚        "recipient": "name",
   â”‚      â”‚        "message": "cleaned message content",
   â”‚      â”‚        "confidence": 0.85,
   â”‚      â”‚        "reasoning": "explanation"
   â”‚      â”‚      }
   â”‚      â”‚
   â”‚      â””â”€â–º Check confidence > 0.7 â†’ Set success: true
   â”‚
   â”œâ”€â–º BRANCH on action type:
   â”‚      â”‚
   â”‚      â”œâ”€â–º ACTION: "send_message" (confidence > 0.7)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€â–º GO TO: TELEGRAM MESSAGE FLOW
   â”‚      â”‚
   â”‚      â””â”€â–º ACTION: "general_chat" OR low confidence
   â”‚             â”‚
   â”‚             â””â”€â–º GO TO: OLLAMA CHAT FLOW
   â”‚
   â””â”€â–º Return response to conversation loop
```

### 4ï¸âƒ£ TELEGRAM MESSAGE FLOW
```
SEND_MESSAGE INTENT DETECTED
   â”‚
   â”œâ”€â–º Extract recipient and message from intent
   â”‚      â”‚
   â”‚      â”œâ”€â–º recipient = intent["recipient"]
   â”‚      â””â”€â–º message = intent["message"]
   â”‚
   â”œâ”€â–º FUZZY MATCH RECIPIENT
   â”‚      â”‚
   â”‚      â”œâ”€â–º Load contacts from config/contacts.json
   â”‚      â”‚      {
   â”‚      â”‚        "john": "+1234567890",
   â”‚      â”‚        "sarah": "+9876543210",
   â”‚      â”‚        ...
   â”‚      â”‚      }
   â”‚      â”‚
   â”‚      â”œâ”€â–º Try exact match (case-insensitive)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€ FOUND â†’ confidence = 1.0, no confirmation needed
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€ NOT FOUND â†’ Try fuzzy matching
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º Use difflib.get_close_matches()
   â”‚      â”‚              â”‚      cutoff = 0.6
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º Calculate similarity ratio
   â”‚      â”‚              â”‚
   â”‚      â”‚              â”œâ”€â–º If ratio < 0.9 â†’ needs_confirmation = true
   â”‚      â”‚              â”‚      â”‚
   â”‚      â”‚              â”‚      â”œâ”€â–º Speak: "Did you mean {name}? Say yes or no."
   â”‚      â”‚              â”‚      â”œâ”€â–º Record 5s audio
   â”‚      â”‚              â”‚      â”œâ”€â–º Transcribe
   â”‚      â”‚              â”‚      â”‚
   â”‚      â”‚              â”‚      â”œâ”€ "yes" â†’ Use matched name
   â”‚      â”‚              â”‚      â”‚
   â”‚      â”‚              â”‚      â””â”€ "no" â†’ Try alternatives
   â”‚      â”‚              â”‚            â”‚
   â”‚      â”‚              â”‚            â”œâ”€ Has alternatives?
   â”‚      â”‚              â”‚            â”‚    â””â”€â–º Ask about next match
   â”‚      â”‚              â”‚            â”‚
   â”‚      â”‚              â”‚            â””â”€ No alternatives?
   â”‚      â”‚              â”‚                 â””â”€â–º "Message cancelled"
   â”‚      â”‚              â”‚
   â”‚      â”‚              â””â”€â–º If ratio >= 0.9 â†’ Auto-accept match
   â”‚      â”‚
   â”‚      â””â”€â–º No match found â†’ Return error message
   â”‚
   â”œâ”€â–º SEND VIA MCP
   â”‚      â”‚
   â”‚      â”œâ”€â–º Call MCPClientSync.send_telegram_message(message, recipient)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Check if MCP connected
   â”‚      â”‚      â”‚      â””â”€â–º If not, connect first
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Build arguments: {"message": text, "recipient": name}
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€â–º asyncio.run(client.call_tool("telegram", "send_telegram_message", args))
   â”‚      â”‚
   â”‚      â”œâ”€â–º MCP CLIENT LAYER
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Create StdioServerParameters
   â”‚      â”‚      â”‚      command: "python"
   â”‚      â”‚      â”‚      args: ["src/mcp_servers/telegram_server.py"]
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Open stdio connection to MCP server
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Initialize ClientSession
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Call session.call_tool(tool_name, arguments)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€â–º Extract text from result.content[0].text
   â”‚      â”‚
   â”‚      â”œâ”€â–º MCP SERVER LAYER
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Receive stdio request
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Parse tool name: "send_telegram_message"
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Extract arguments: recipient, message
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Call TelethonUserClient.send_message(recipient, message)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€â–º Return TextContent with result
   â”‚      â”‚
   â”‚      â”œâ”€â–º TELETHON USER CLIENT LAYER
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Load config/contacts.json
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Resolve recipient:
   â”‚      â”‚      â”‚      â”‚
   â”‚      â”‚      â”‚      â”œâ”€â–º Is it a contact name? â†’ Look up phone number
   â”‚      â”‚      â”‚      â”œâ”€â–º Is it @username? â†’ Use as-is
   â”‚      â”‚      â”‚      â””â”€â–º Is it phone number? â†’ Use as-is
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Connect to Telegram via Telethon
   â”‚      â”‚      â”‚      â”‚
   â”‚      â”‚      â”‚      â”œâ”€â–º Use session file: config/telegram_session.session
   â”‚      â”‚      â”‚      â”œâ”€â–º API ID and API Hash from .env
   â”‚      â”‚      â”‚      â””â”€â–º Authenticate as USER account (not bot)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Get entity (user or chat)
   â”‚      â”‚      â”‚      await client.get_entity(recipient)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â”œâ”€â–º Send message
   â”‚      â”‚      â”‚      await client.send_message(entity, message)
   â”‚      â”‚      â”‚
   â”‚      â”‚      â””â”€â–º Return result:
   â”‚      â”‚             {
   â”‚      â”‚               "success": true,
   â”‚      â”‚               "message_id": 12345,
   â”‚      â”‚               "recipient": "john",
   â”‚      â”‚               "resolved_as": "+1234567890"
   â”‚      â”‚             }
   â”‚      â”‚
   â”‚      â””â”€â–º TELEGRAM API
   â”‚             â”‚
   â”‚             â””â”€â–º Message delivered to recipient
   â”‚
   â”œâ”€â–º UPDATE CONTEXT
   â”‚      â”‚
   â”‚      â””â”€â–º intent_parser.update_context(user_text, response, recipient)
   â”‚             â”œâ”€â–º Store in conversation_context list
   â”‚             â””â”€â–º Keep only last 5 exchanges
   â”‚
   â””â”€â–º RETURN RESPONSE
          â”‚
          â”œâ”€ SUCCESS â†’ "Message sent to {recipient}!"
          â”‚
          â””â”€ FAILURE â†’ "Failed to send message: {error}"
```

### 5ï¸âƒ£ OLLAMA CHAT FLOW
```
GENERAL_CHAT OR NON-MESSAGE INTENT
   â”‚
   â”œâ”€â–º Build context from conversation_history
   â”‚      â”‚
   â”‚      â”œâ”€â–º Get last 3 user-AI exchanges
   â”‚      â”‚      [
   â”‚      â”‚        ("what's the weather", "It's sunny today"),
   â”‚      â”‚        ("and tomorrow?", "Tomorrow will be rainy"),
   â”‚      â”‚      ]
   â”‚      â”‚
   â”‚      â””â”€â–º Format as:
   â”‚             "Previous conversation:
   â”‚              User: what's the weather
   â”‚              Gemma: It's sunny today
   â”‚              User: and tomorrow?
   â”‚              Gemma: Tomorrow will be rainy
   â”‚
   â”‚              Current question:
   â”‚              User: {current_prompt}"
   â”‚
   â”œâ”€â–º Send to Ollama API
   â”‚      â”‚
   â”‚      â”œâ”€â–º Endpoint: http://localhost:11434/api/generate
   â”‚      â”‚
   â”‚      â”œâ”€â–º Request:
   â”‚      â”‚      {
   â”‚      â”‚        "model": "gemma2:2b",
   â”‚      â”‚        "prompt": full_prompt_with_context,
   â”‚      â”‚        "stream": false
   â”‚      â”‚      }
   â”‚      â”‚
   â”‚      â”œâ”€â–º Response:
   â”‚      â”‚      {
   â”‚      â”‚        "response": "AI generated response...",
   â”‚      â”‚        ...
   â”‚      â”‚      }
   â”‚      â”‚
   â”‚      â””â”€â–º Extract and clean response
   â”‚             â”‚
   â”‚             â”œâ”€â–º Take first 2 sentences (for brevity)
   â”‚             â””â”€â–º Store in conversation_history
   â”‚
   â””â”€â–º RETURN RESPONSE
          â”‚
          â””â”€â–º Response spoken to user via TTS
```

---

## ğŸ“¦ Component Breakdown

### Core Components

#### 1. AutoVoiceAssistant (`auto_voice_assistant.py`)
**Purpose**: Main orchestrator - handles voice activation, recording, transcription, and coordination

**Key Methods**:
- `__init__()`: Initialize OpenAI, Ollama, TTS, MCP client, contacts
- `run()`: Main loop for voice activation listening
- `detect_activation(text)`: Check for [hello, hi, computer, assistant]
- `start_conversation()`: Enter 60s conversation mode
- `record_and_transcribe_fast(duration)`: Record audio â†’ OpenAI Whisper â†’ text
- `handle_user_input(user_text)`: Route to Telegram or Ollama based on intent
- `fuzzy_match_contact(name)`: Match spoken name to contacts.json with confirmation
- `speak(text)`: Output via local TTS or OpenAI TTS
- `log_conversation()`: Save to data/conversations.json

**State Management**:
- `in_conversation`: Boolean flag
- `last_interaction_time`: Timestamp for timeout
- `conversation_history`: List of (user_text, ai_response) tuples
- `is_processing`: Prevent parallel processing

**Audio Settings**:
- Sample rate: 16000 Hz
- Channels: 1 (mono)
- Chunk duration: 2s (activation listening)
- Command duration: 8s (user input)
- Volume thresholds: 0.008 (activation), 0.004 (conversation)

#### 2. IntentParser (`intent_parser.py`)
**Purpose**: AI-powered natural language understanding using GPT-4o-mini

**Key Methods**:
- `parse(user_text, conversation_history)`: Main parsing function
- `update_context(user_text, response, recipient)`: Track conversation for pronoun resolution
- `_fallback_parse(user_text)`: Simple keyword matching if GPT fails

**System Prompt Logic**:
```
Analyze user commands and extract:
1. Action type (send_message vs general_chat)
2. Recipient (with pronoun resolution using context)
3. Clean message content (remove filler words)

RULES:
- "saying that X" â†’ message: "X" (not "that X")
- "also tell him" â†’ use LAST recipient from context
- Handle pronouns: him, her, them, also
```

**Context Tracking**:
- Stores last 5 message exchanges
- Each entry: {user, assistant, recipient}
- Used to resolve pronouns like "him" â†’ "john"

**Output Format**:
```json
{
  "action": "send_message" | "general_chat",
  "recipient": "john",
  "message": "cleaned text",
  "confidence": 0.85,
  "reasoning": "explanation",
  "success": true/false
}
```

#### 3. MCPClient (`mcp_client.py`)
**Purpose**: Connect to MCP servers and execute tools programmatically

**Key Classes**:
- `MCPClient`: Async client for MCP protocol
- `MCPClientSync`: Synchronous wrapper for voice assistant

**Key Methods**:
- `connect_server(name, command, args)`: Establish stdio connection to MCP server
- `call_tool(server_name, tool_name, arguments)`: Execute MCP tool
- `list_tools(server_name)`: Discover available tools

**Connection Flow**:
```python
server_params = StdioServerParameters(
    command="python",
    args=["src/mcp_servers/telegram_server.py"]
)
async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write) as session:
        await session.initialize()
        result = await session.call_tool(tool_name, args)
```

#### 4. TelegramServer (`telegram_server.py`)
**Purpose**: MCP server exposing Telegram capabilities via stdio protocol

**Available Tools**:
1. `send_telegram_message`: Send text from user account
   - Parameters: recipient (name/@username/phone), message
2. `send_telegram_photo`: Send photo
   - Parameters: photo_path, caption, chat_id
3. `send_telegram_document`: Send file
   - Parameters: document_path, caption, chat_id
4. `get_telegram_bot_info`: Get bot details
5. `get_telegram_chat_info`: Get chat details

**MCP Protocol**:
- Transport: stdio (stdin/stdout)
- Format: JSON-RPC
- Decorators: @app.list_tools(), @app.call_tool()

**Execution Flow**:
```
Request â†’ stdio â†’ @call_tool() â†’ TelethonUserClient â†’ Telegram API
Response â† stdio â† TextContent â† Result â† API Response
```

#### 5. TelethonUserClient (`telethon_user_client.py`)
**Purpose**: Actual Telegram API integration using Telethon (user account, not bot)

**Key Features**:
- Authenticates as user account (not bot)
- Supports contact names, @usernames, phone numbers
- Loads contacts from config/contacts.json
- Session persistence in config/telegram_session.session

**Key Methods**:
- `start()`: Initialize and authenticate Telethon client
- `send_message(recipient, message)`: Resolve recipient and send
- `send_photo()`, `send_document()`: Media sending
- `get_me()`: Get current user info
- `_resolve_recipient(identifier)`: Convert name/username/phone to entity

**Recipient Resolution Logic**:
```
Input: "john"
  â””â”€â–º Load contacts.json â†’ {"john": "+1234567890"}
      â””â”€â–º Use phone number to get entity
          â””â”€â–º Send message

Input: "@johndoe"
  â””â”€â–º Use username directly
      â””â”€â–º Get entity by username
          â””â”€â–º Send message

Input: "+1234567890"
  â””â”€â–º Use phone directly
      â””â”€â–º Get entity by phone
          â””â”€â–º Send message
```

---

## ğŸ—‚ï¸ Data Structures

### Configuration Files

#### `config/.env`
```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma2:2b

# TTS
USE_OPENAI_TTS=false  # false = local, true = OpenAI

# Telegram Bot (legacy, for bot approach)
TELEGRAM_BOT_TOKEN=8364724814:...
TELEGRAM_CHAT_ID=1237082783

# Telethon (for user account messaging)
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
TELEGRAM_PHONE=+1234567890
```

#### `config/contacts.json`
```json
{
  "john": "+1234567890",
  "sarah": "+9876543210",
  "mike": "+1122334455",
  "emma": "@emma_username"
}
```

#### `data/conversations.json`
```json
[
  {
    "id": 1,
    "timestamp": "2024-11-03 15:30:22",
    "user": "send message to john saying hello",
    "ai": "Message sent to john!"
  },
  {
    "id": 2,
    "timestamp": "2024-11-03 15:31:05",
    "user": "what's the weather",
    "ai": "I don't have access to weather data currently."
  }
]
```

---

## ğŸ”€ Key Algorithms

### 1. Fuzzy Contact Matching
```python
def fuzzy_match_contact(spoken_name: str) -> dict:
    # Step 1: Exact match (case-insensitive)
    if spoken_name.lower() in contacts:
        return {matched: True, name: spoken_name, confidence: 1.0}

    # Step 2: Fuzzy matching
    import difflib
    matches = difflib.get_close_matches(
        spoken_name.lower(),
        contact_names,
        n=3,  # Top 3 matches
        cutoff=0.6  # 60% similarity minimum
    )

    if matches:
        best_match = matches[0]
        confidence = SequenceMatcher(None, spoken_name, best_match).ratio()

        # Step 3: Confirmation check
        if confidence < 0.9:  # 90% threshold
            needs_confirmation = True
            # Voice assistant will ask: "Did you mean {best_match}?"

        return {
            matched: True,
            name: best_match,
            confidence: confidence,
            needs_confirmation: needs_confirmation,
            alternatives: matches[1:]
        }

    return {matched: False}
```

### 2. Timeout Management
```python
# On conversation start
in_conversation = True
last_interaction_time = time.time()
timeout = 60  # seconds

# In conversation loop
while in_conversation:
    elapsed = time.time() - last_interaction_time

    if elapsed > timeout:
        speak("I'm going back to sleep now.")
        in_conversation = False
        break

    remaining = timeout - elapsed
    user_text = record_and_transcribe(8, f"Listening... ({remaining}s left)")

    if user_text:
        # Reset timer on valid input
        last_interaction_time = time.time()
        process_input(user_text)
    else:
        # No input - let timer continue (don't reset)
        continue
```

### 3. Volume-Based Voice Detection
```python
def record_and_transcribe(duration, description):
    # Record audio
    audio_data = sd.rec(duration * sample_rate, ...)
    sd.wait()

    # Volume check
    volume = np.sqrt(np.mean(audio_data**2))

    # Different thresholds for different modes
    if description == "Listening...":  # Activation mode
        threshold = 0.008  # Stricter (require louder voice)
    else:  # Conversation mode
        threshold = 0.004  # More sensitive

    if volume < threshold:
        return ""  # Too quiet, ignore

    # Amplify and normalize
    audio_data = np.clip(audio_data * 1.5, -1.0, 1.0)

    # Send to OpenAI Whisper
    transcript = openai_client.audio.transcriptions.create(
        model="gpt-4o-mini-transcribe",
        file=audio_wav,
        language="en"
    )

    return transcript.strip()
```

---

## ğŸŒŠ Complete User Journey Examples

### Example 1: Send Single Message
```
â”Œâ”€ User says: "Hello"
â”‚
â”œâ”€ Voice Assistant:
â”‚    â”œâ”€â–º Detects activation word "hello"
â”‚    â”œâ”€â–º Enters conversation mode (60s timer starts)
â”‚    â””â”€â–º Speaks: "Hi! What can I help you with?"
â”‚
â”œâ”€ User says: "Send message to John saying hello how are you"
â”‚
â”œâ”€ Voice Assistant:
â”‚    â”œâ”€â–º Records 8s audio
â”‚    â”œâ”€â–º Transcribes: "Send message to John saying hello how are you"
â”‚    â”œâ”€â–º Intent Parser (GPT-4o-mini):
â”‚    â”‚     â€¢ action: "send_message"
â”‚    â”‚     â€¢ recipient: "john"
â”‚    â”‚     â€¢ message: "hello how are you"
â”‚    â”‚     â€¢ confidence: 0.95
â”‚    â”‚
â”‚    â”œâ”€â–º Fuzzy match "john" in contacts.json
â”‚    â”‚     â€¢ Exact match found: "john" â†’ "+1234567890"
â”‚    â”‚     â€¢ No confirmation needed (confidence: 1.0)
â”‚    â”‚
â”‚    â”œâ”€â–º Call MCP Client
â”‚    â”‚     â”œâ”€â–º Connect to telegram MCP server
â”‚    â”‚     â”œâ”€â–º Call tool: send_telegram_message
â”‚    â”‚     â”‚     args: {recipient: "john", message: "hello how are you"}
â”‚    â”‚     â”‚
â”‚    â”‚     â”œâ”€â–º MCP Server receives request
â”‚    â”‚     â”‚     â”œâ”€â–º Parse recipient: "john"
â”‚    â”‚     â”‚     â”œâ”€â–º Load contacts.json
â”‚    â”‚     â”‚     â”œâ”€â–º Resolve "john" â†’ "+1234567890"
â”‚    â”‚     â”‚     â”‚
â”‚    â”‚     â”‚     â”œâ”€â–º Telethon sends message
â”‚    â”‚     â”‚     â”‚     â”œâ”€â–º Get entity: +1234567890
â”‚    â”‚     â”‚     â”‚     â””â”€â–º Send: "hello how are you"
â”‚    â”‚     â”‚     â”‚
â”‚    â”‚     â”‚     â””â”€â–º Return: "âœ… Message sent successfully to john"
â”‚    â”‚     â”‚
â”‚    â”‚     â””â”€â–º MCP Client returns result to voice assistant
â”‚    â”‚
â”‚    â”œâ”€â–º Update conversation context
â”‚    â”‚     â€¢ Store: user="send message...", recipient="john"
â”‚    â”‚
â”‚    â”œâ”€â–º Log to conversations.json
â”‚    â”‚
â”‚    â””â”€â–º Speak: "Message sent to john!"
â”‚
â””â”€ Conversation continues (timer reset)...
```

### Example 2: Follow-up Message with Pronoun
```
â”Œâ”€ User says: "Hello"
â”‚
â”œâ”€ Assistant: "Hi! What can I help you with?"
â”‚
â”œâ”€ User: "Send message to Sarah saying I'll be late"
â”‚
â”œâ”€ Assistant:
â”‚    â”œâ”€â–º Intent: send_message, recipient: "sarah", message: "I'll be late"
â”‚    â”œâ”€â–º Fuzzy match: "sarah" â†’ exact match
â”‚    â”œâ”€â–º Send via MCP â†’ Telegram
â”‚    â”œâ”€â–º Update context: user="send message...", recipient="sarah"
â”‚    â””â”€â–º Speak: "Message sent to Sarah!"
â”‚
â”œâ”€ User: "Also tell her about the meeting"
â”‚
â”œâ”€ Assistant:
â”‚    â”œâ”€â–º Intent Parser (with context):
â”‚    â”‚     â€¢ Context shows: last recipient = "sarah"
â”‚    â”‚     â€¢ GPT-4o-mini detects "her" = "sarah" (pronoun resolution)
â”‚    â”‚     â€¢ action: "send_message"
â”‚    â”‚     â€¢ recipient: "sarah"  â† Resolved from context!
â”‚    â”‚     â€¢ message: "about the meeting"
â”‚    â”‚
â”‚    â”œâ”€â–º No need for fuzzy match (already resolved)
â”‚    â”œâ”€â–º Send via MCP â†’ Telegram
â”‚    â”œâ”€â–º Update context: recipient="sarah"
â”‚    â””â”€â–º Speak: "Message sent to Sarah!"
â”‚
â””â”€ Conversation continues...
```

### Example 3: Fuzzy Match with Confirmation
```
â”Œâ”€ User: "Send message to Jon saying hello"
â”‚         (Note: Spelled "Jon" but contact is "John")
â”‚
â”œâ”€ Assistant:
â”‚    â”œâ”€â–º Intent: send_message, recipient: "jon", message: "hello"
â”‚    â”‚
â”‚    â”œâ”€â–º Fuzzy match:
â”‚    â”‚     â€¢ No exact match for "jon"
â”‚    â”‚     â€¢ difflib.get_close_matches("jon", ["john", "sarah", ...])
â”‚    â”‚     â€¢ Best match: "john" (similarity: 0.88)
â”‚    â”‚     â€¢ confidence < 0.9 â†’ needs_confirmation = True
â”‚    â”‚
â”‚    â”œâ”€â–º Speak: "Did you mean john? Say yes or no."
â”‚    â”‚
â”‚    â”œâ”€â–º Record 5s audio â†’ "Yes"
â”‚    â”‚
â”‚    â”œâ”€â–º Confirmation received: "yes" detected
â”‚    â”‚     â€¢ Use matched name: "john"
â”‚    â”‚
â”‚    â”œâ”€â–º Send via MCP â†’ Telegram to "john"
â”‚    â”‚
â”‚    â””â”€â–º Speak: "Message sent to john!"
â”‚
â””â”€ Done
```

### Example 4: General Chat (No Message Intent)
```
â”Œâ”€ User: "Hello"
â”‚
â”œâ”€ Assistant: "Hi! What can I help you with?"
â”‚
â”œâ”€ User: "What's the weather today?"
â”‚
â”œâ”€ Assistant:
â”‚    â”œâ”€â–º Intent Parser:
â”‚    â”‚     â€¢ action: "general_chat"
â”‚    â”‚     â€¢ confidence: 0.92
â”‚    â”‚     â€¢ No message keywords detected
â”‚    â”‚
â”‚    â”œâ”€â–º Route to Ollama LLM (not Telegram)
â”‚    â”‚     â”œâ”€â–º Build context from conversation_history
â”‚    â”‚     â”‚     Previous conversation: (none)
â”‚    â”‚     â”‚     Current question: "What's the weather today?"
â”‚    â”‚     â”‚
â”‚    â”‚     â”œâ”€â–º Send to Ollama gemma2:2b
â”‚    â”‚     â”‚     POST http://localhost:11434/api/generate
â”‚    â”‚     â”‚
â”‚    â”‚     â””â”€â–º Response: "I don't have access to weather data, but you can check a weather app."
â”‚    â”‚
â”‚    â”œâ”€â–º Store in conversation_history:
â”‚    â”‚     ("What's the weather today?", "I don't have access...")
â”‚    â”‚
â”‚    â””â”€â–º Speak: "I don't have access to weather data, but you can check a weather app."
â”‚
â”œâ”€ User: "Thanks"
â”‚
â”œâ”€ Assistant:
â”‚    â”œâ”€â–º Detects exit keyword: "thanks"
â”‚    â””â”€â–º Speak: "Goodbye! Say 'Hello' when you need me again."
â”‚
â””â”€ Return to listening mode
```

### Example 5: Timeout Scenario
```
â”Œâ”€ User: "Hello"
â”‚
â”œâ”€ Assistant: "Hi! What can I help you with?"
â”‚    â€¢ Timer starts: 60s
â”‚
â”œâ”€ User: "What's 2+2?"
â”‚    â€¢ Timer: 10s elapsed
â”‚
â”œâ”€ Assistant: "2+2 equals 4."
â”‚    â€¢ Timer reset to 0s (user spoke)
â”‚
â”œâ”€ [Silence for 30 seconds...]
â”‚    â€¢ Timer: 30s elapsed
â”‚    â€¢ Assistant: [Shows "ğŸ”‡ Silence... (30s until timeout)"]
â”‚
â”œâ”€ [Silence for another 20 seconds...]
â”‚    â€¢ Timer: 50s elapsed
â”‚    â€¢ Assistant: [Shows "â° Timing out in 10s..."]
â”‚
â”œâ”€ [Silence for final 10 seconds...]
â”‚    â€¢ Timer: 60s elapsed
â”‚
â”œâ”€ Assistant:
â”‚    â”œâ”€â–º Timeout triggered!
â”‚    â”œâ”€â–º Set in_conversation = False
â”‚    â””â”€â–º Speak: "I'm going back to sleep now. Say 'Hello' to wake me up!"
â”‚
â””â”€ Return to listening mode
```

---

## ğŸ§© Technology Stack

### Core Technologies
- **Python 3.8+**: Main language
- **OpenAI API**:
  - STT: gpt-4o-mini-transcribe ($0.003/min)
  - Intent Understanding: gpt-4o-mini
  - TTS (optional): tts-1 ($0.015/min)
- **Ollama**: Local LLM inference (gemma2:2b)
- **Telethon**: Telegram MTProto API (user account)
- **MCP (Model Context Protocol)**: Standardized tool protocol

### Libraries
- **Audio**:
  - `sounddevice`: Real-time audio recording
  - `numpy`: Audio data processing
  - `wave`: WAV file creation
  - `pyttsx3`: Local TTS engine
- **Telegram**:
  - `telethon`: User account API
  - `python-telegram-bot`: Bot API (legacy)
- **MCP**:
  - `mcp`: MCP SDK
  - `mcp.server`, `mcp.client`: Server/client implementations
- **Utilities**:
  - `dotenv`: Environment variables
  - `requests`: HTTP requests (Ollama)
  - `difflib`: Fuzzy string matching
  - `asyncio`: Async/await support
  - `logging`: Application logging

---

## ğŸ“Š Cost Analysis

### Monthly Costs (1 hour daily usage)
```
Assumptions:
- 30 conversations/day Ã— 30 days = 900 conversations/month
- Avg conversation: 3 exchanges = 6 audio chunks
- Avg audio length: 5 seconds/chunk

STT (OpenAI gpt-4o-mini-transcribe):
  â€¢ 900 conv Ã— 6 chunks Ã— 5 seconds = 27,000 seconds = 450 minutes
  â€¢ $0.003/min Ã— 450 = $1.35/month

Intent Understanding (GPT-4o-mini):
  â€¢ 900 conv Ã— 3 intents = 2,700 API calls
  â€¢ ~100 tokens/call = 270K tokens
  â€¢ $0.15/1M input tokens = $0.04/month

TTS (Local - pyttsx3):
  â€¢ FREE

LLM (Ollama gemma2:2b):
  â€¢ FREE (local)

TOTAL: ~$1.39/month
```

If using OpenAI TTS: +$6.75/month ($0.015/min Ã— 450 min)

---

## ğŸ”’ Security Considerations

### Authentication
- **Telegram Session**: Stored in `config/telegram_session.session`
  - Contains auth token for user account
  - Protected by file permissions (600)
  - Should NOT be committed to git
- **API Keys**: Stored in `config/.env`
  - OpenAI API key
  - Telegram API ID/Hash
  - Protected by .gitignore

### Privacy
- **Conversation Logs**: Stored in `data/conversations.json`
  - Contains user text and AI responses
  - No audio recordings saved
  - Can be disabled if needed
- **Voice Data**:
  - Processed in-memory
  - Sent to OpenAI Whisper API (encrypted)
  - Not stored on disk

### Network
- **Ollama**: Local (localhost:11434) - no external calls
- **OpenAI**: HTTPS encrypted
- **Telegram**: MTProto encrypted (via Telethon)
- **MCP**: Stdio transport (local only, no network)

---

## ğŸš€ Deployment Options

### 1. Manual Mode (Development)
```bash
python main.py
# Terminal stays open, shows logs
# Press Ctrl+C to stop
```

### 2. Background Mode (Production)
```bash
./scripts/start_gemma_background.sh
# Runs as daemon, logs to logs/gemma.log
# Use ./scripts/stop_gemma.sh to stop
```

### 3. Auto-Start Service (macOS)
```bash
./scripts/install_service.sh
# Installs LaunchAgent
# Starts on login automatically
# Logs to ~/Library/Logs/gemma_voice_assistant.log
```

---

## ğŸ› Error Handling

### Voice Assistant Level
```python
try:
    user_text = record_and_transcribe(...)
except Exception as e:
    print(f"Recording error: {e}")
    # Continue listening, don't crash

try:
    response = handle_user_input(user_text)
except Exception as e:
    print(f"Processing error: {e}")
    speak("Sorry, I had trouble with that.")
```

### Intent Parser Level
```python
try:
    parsed = gpt_mini_api_call(...)
except Exception as e:
    # Fallback to keyword matching
    return _fallback_parse(user_text)
```

### MCP Client Level
```python
try:
    result = await session.call_tool(...)
except Exception as e:
    logger.error(f"MCP call failed: {e}")
    return "Failed to send message."
```

### Telethon Level
```python
try:
    entity = await client.get_entity(recipient)
except Exception as e:
    return {
        "success": False,
        "error": f"Could not find recipient: {e}"
    }
```

---

## ğŸ“ Logging Strategy

### Log Files
- `logs/gemma.log`: Main application log
- `gemma_service.log`: Background service log
- `data/conversations.json`: User conversation history

### Log Levels
```python
logger.info("âœ… Normal operation")
logger.warning("âš ï¸ Non-critical issue")
logger.error("âŒ Error occurred")
```

### Example Log Entry
```
2024-11-03 15:30:22 - INFO - ğŸ™ï¸ Voice Activation Mode Active!
2024-11-03 15:30:24 - INFO - ğŸ‘‚ hello
2024-11-03 15:30:24 - INFO - ğŸ”¥ Activation detected: 'hello'
2024-11-03 15:30:25 - INFO - ğŸ—£ï¸ Gemma: Hi! What can I help you with?
2024-11-03 15:30:30 - INFO - ğŸ‘‚ send message to john saying hello
2024-11-03 15:30:30 - INFO - ğŸ§  Understanding intent with context...
2024-11-03 15:30:31 - INFO - âœ… Intent: send_message | Recipient: john | Confidence: 0.95
2024-11-03 15:30:31 - INFO - ğŸ“± Detected message intent
2024-11-03 15:30:31 - INFO - ğŸ“ Calling telegram.send_telegram_message
2024-11-03 15:30:32 - INFO - âœ… Message sent successfully to john
2024-11-03 15:30:32 - INFO - ğŸ—£ï¸ Gemma: Message sent to john!
```

---

## ğŸ¯ Future Enhancements (Potential)

### 1. Multi-Platform Support
- Add WhatsApp MCP server
- Add Slack MCP server
- Add Email MCP server
- Unified contact management

### 2. Advanced Features
- Voice command customization
- Multiple activation words
- Different voices per contact
- Scheduled messages
- Message templates
- Group chat support

### 3. Intelligence Improvements
- Better pronoun resolution
- Context across sessions (persistent memory)
- Learning user preferences
- Personalized responses

### 4. Platform Expansion
- Linux support
- Windows support
- Mobile app (iOS/Android)
- Web interface

---

## ğŸ”„ State Machine Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               SYSTEM STATES                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚  â”‚   IDLE     â”‚  â† Initial state                â”‚
â”‚  â”‚  (Waiting) â”‚                                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚        â”‚                                         â”‚
â”‚        â”‚ Initialization complete                 â”‚
â”‚        â”‚                                         â”‚
â”‚        â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚   LISTENING    â”‚  â† Background listening      â”‚
â”‚  â”‚  (Activation   â”‚     for activation word     â”‚
â”‚  â”‚   Detection)   â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚           â”‚                                      â”‚
â”‚           â”‚ Activation word detected            â”‚
â”‚           â”‚ [hello, hi, computer, assistant]    â”‚
â”‚           â”‚                                      â”‚
â”‚           â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚   CONVERSATION   â”‚  â† Active session         â”‚
â”‚  â”‚    (Active)      â”‚     60s timeout           â”‚
â”‚  â”‚                  â”‚                            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                            â”‚
â”‚  â”‚  â”‚ Listeningâ”‚â—„â”€â”€â”¤  â† Recording user          â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚                            â”‚
â”‚  â”‚       â”‚          â”‚                            â”‚
â”‚  â”‚       â”œâ”€ Transcribing                        â”‚
â”‚  â”‚       â”‚          â”‚                            â”‚
â”‚  â”‚       â–¼          â”‚                            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                            â”‚
â”‚  â”‚  â”‚Processingâ”‚   â”‚  â† Intent parsing          â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚     + execution            â”‚
â”‚  â”‚       â”‚          â”‚                            â”‚
â”‚  â”‚       â”œâ”€ Responding                           â”‚
â”‚  â”‚       â”‚          â”‚                            â”‚
â”‚  â”‚       â–¼          â”‚                            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                            â”‚
â”‚  â”‚  â”‚ Speaking â”‚   â”‚  â† TTS output              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚                            â”‚
â”‚  â”‚       â”‚          â”‚                            â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â† Loop back               â”‚
â”‚  â”‚                  â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚         â”‚                                        â”‚
â”‚         â”‚ Exit command OR timeout               â”‚
â”‚         â”‚                                        â”‚
â”‚         â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚   LISTENING    â”‚  â† Back to activation       â”‚
â”‚  â”‚  (Activation   â”‚     detection               â”‚
â”‚  â”‚   Detection)   â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                  â”‚
â”‚  ERROR STATE (any level):                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚   RECOVERING   â”‚  â† Handles exceptions       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     Logs error              â”‚
â”‚           â”‚             Returns to LISTENING    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â–º LISTENING                     â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š API Reference Summary

### OpenAI APIs Used

#### 1. Whisper (STT)
```python
transcript = openai_client.audio.transcriptions.create(
    model="gpt-4o-mini-transcribe",  # Latest, 50% cheaper
    file=("audio.wav", audio_buffer),
    language="en",
    response_format="text"
)
```

#### 2. GPT-4o-mini (Intent Understanding)
```python
response = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_query}
    ],
    temperature=0.1,
    response_format={"type": "json_object"}
)
```

#### 3. TTS (Optional)
```python
response = openai_client.audio.speech.create(
    model="tts-1",
    voice="nova",
    input=text,
    speed=1.1
)
```

### Ollama API

#### Generate Response
```bash
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "gemma2:2b",
  "prompt": "You are Gemma...",
  "stream": false
}
```

### Telethon API

#### Send Message
```python
await client.send_message(
    entity=recipient_entity,
    message=text
)
```

#### Get Entity
```python
entity = await client.get_entity(
    identifier  # Can be: phone, username, or contact
)
```

---

## ğŸ¬ Conclusion

This system combines multiple cutting-edge technologies to create a Siri-like voice assistant with Telegram integration. The modular architecture using MCP makes it extensible to other platforms, while the AI-powered intent understanding provides a natural conversational experience.

### Key Strengths:
âœ… **Natural Language**: GPT-4o-mini understands intent naturally
âœ… **Context-Aware**: Tracks conversation history for pronouns
âœ… **Fuzzy Matching**: Handles misspelled names with confirmation
âœ… **Cost-Effective**: Uses local Ollama LLM for chat (~$1.39/month)
âœ… **Modular**: MCP architecture allows easy platform expansion
âœ… **User-Friendly**: Works like Siri with voice activation
âœ… **Real Account**: Sends from user's Telegram (not bot)

### Use Cases:
- Hands-free Telegram messaging while driving/cooking
- Voice-controlled contact management
- Accessible communication for users with disabilities
- Quick message sending without typing
- Multi-tasking productivity tool

---

**Project Status**: âœ… Production Ready
**Last Updated**: November 2024
**Version**: 1.0