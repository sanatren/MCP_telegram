# ğŸ™ï¸ Gemma Voice Assistant

A real-time voice assistant that works like Siri, powered by local Ollama and OpenAI's latest speech models.

## âœ¨ Features

- ğŸ¤ **Voice Activation**: Say "Hello", "Hi", "Computer", or "Assistant" to activate
- ğŸ§  **Local AI**: Uses Ollama Gemma for private, offline responses  
- ğŸŒ **OpenAI Speech**: Latest gpt-4o-mini-transcribe for accurate STT (50% cheaper)
- â° **Smart Timeout**: 60-second conversation timeout like Siri
- ğŸ’¬ **Context Memory**: Remembers conversation history within session
- ğŸ“Š **Web Dashboard**: Optional visual interface to view conversations
- ğŸ”„ **Background Service**: Runs silently, always listening

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Ollama installed and running (`ollama serve`)
- OpenAI API key
- Microphone access permissions

### Installation

1. **Install dependencies:**
   ```bash
   pip install -r config/requirements.txt
   ```

2. **Configure environment:**
   ```bash
   cp config/.env.example config/.env
   # Edit config/.env with your OpenAI API key
   ```

3. **Run the assistant:**
   ```bash
   python main.py
   ```

## ğŸ“ Project Structure

```
gemma-voice-assistant/
â”œâ”€â”€ main.py                    # Main entry point
â”œâ”€â”€ run_dashboard.py           # Dashboard entry point
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ .env                   # Environment variables
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ *.plist               # macOS service configs
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ core/                  # Core voice assistant
â”‚   â”‚   â””â”€â”€ auto_voice_assistant.py
â”‚   â””â”€â”€ dashboard/             # Web dashboard
â”‚       â”œâ”€â”€ dashboard.py
â”‚       â””â”€â”€ templates/
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ start_gemma_background.sh
â”‚   â”œâ”€â”€ stop_gemma.sh
â”‚   â”œâ”€â”€ install_service.sh
â”‚   â””â”€â”€ uninstall_service.sh
â”œâ”€â”€ data/                      # Data files
â”‚   â””â”€â”€ conversations.json    # Conversation history
â”œâ”€â”€ logs/                      # Log files
â”‚   â”œâ”€â”€ gemma.log
â”‚   â””â”€â”€ *.pid
â””â”€â”€ docs/                      # Documentation
    â””â”€â”€ OPENAI_MODELS_2024.md
```

## ğŸ¯ Usage

### Manual Mode (Terminal)
```bash
python main.py
```
Shows real-time output and voice detection.

### Background Mode (Always-On)
```bash
./scripts/start_gemma_background.sh
```
Runs silently in background, always listening.

### Web Dashboard
```bash
python run_dashboard.py
# Open http://localhost:5001
```
View conversation history and status.

### Auto-Start Service (macOS)
```bash
./scripts/install_service.sh
```
Starts automatically on login.

## ğŸ¤ Voice Commands

**Activation Words:**
- "Hello" 
- "Hi"
- "Computer"
- "Assistant"

**Exit Commands:**
- "Goodbye"
- "Bye" 
- "Thanks"
- "That's all"
- Or wait 60 seconds for auto-timeout

## âš™ï¸ Configuration

Edit `config/.env`:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_api_key_here

# TTS Options: 'false'=free local, 'true'=paid OpenAI
USE_OPENAI_TTS=false

# Ollama Configuration  
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma2:2b
```

## ğŸ”§ Scripts

| Script | Purpose |
|--------|---------|
| `main.py` | Run assistant in terminal |
| `run_dashboard.py` | Start web dashboard |
| `scripts/start_gemma_background.sh` | Start background service |
| `scripts/stop_gemma.sh` | Stop background service |
| `scripts/install_service.sh` | Install auto-start service |
| `scripts/uninstall_service.sh` | Remove auto-start service |

## ğŸ’° Costs

- **STT**: $0.003/minute (gpt-4o-mini-transcribe - 50% cheaper)
- **TTS**: Free (local) or $0.015/minute (OpenAI)
- **LLM**: Free (local Ollama)
- **Total**: ~$0.63/month for 1 hour daily usage

## ğŸ” Troubleshooting

**Assistant not responding:**
1. Check microphone permissions
2. Increase microphone volume in System Preferences
3. Ensure Ollama is running: `ollama serve`
4. Check logs: `tail -f logs/gemma.log`

**Service won't start:**
1. Run `./scripts/stop_gemma.sh` first
2. Check for conflicting processes: `ps aux | grep main.py`

## ğŸ¯ Examples

**Basic Usage:**
```
ğŸ‘¤ "Hello"
ğŸ—£ï¸ "Hi! What can I help you with?"
ğŸ‘¤ "What's 2+2?"
ğŸ—£ï¸ "2+2 equals 4."
ğŸ‘¤ "Thanks"
ğŸ—£ï¸ "Goodbye! Say 'Hello' when you need me again."
```

**Context Conversation:**
```
ğŸ‘¤ "Hello"
ğŸ—£ï¸ "Hi! What can I help you with?"
ğŸ‘¤ "Tell me about cats"
ğŸ—£ï¸ "Cats are independent pets known for hunting and sleeping."
ğŸ‘¤ "How long do they live?"
ğŸ—£ï¸ "Cats typically live 12-18 years, depending on their health and care."
```

## ğŸ“ˆ Monitoring

- **Logs**: `logs/gemma.log`
- **Dashboard**: http://localhost:5001
- **Process Status**: `ps aux | grep main.py`
- **Conversations**: `data/conversations.json`

---

**Built with â¤ï¸ using OpenAI's latest 2024 models and local Ollama**